---
title: "Reading in Multiple Data Files at Once"
author: "Mike Tapp, Data Director"
date: "20-05-2022"
categories: ["purrr"]
tags: ["import_files", "load_files"]
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_knit$set(root.dir = "/Volumes/GoogleDrive/My Drive/Share_Clients/Data Science Project Work/Slack Overflow/reading_multiple_files/data")
```

#### *Answer originally provided by Mike Tapp, Data Director*

## The Problem

Quite often, we might have data spread across multiple files. This could be multiple listening exports, survey responses etc. It would be quite time consuming to read them all in one by one. In this example, we're going to look at a solution at is able to extract the file names from a directory and then read in the files that match the strings you have extracted in one go using the `map()` function.


## Extracting the names

R will always need to know the exact names of the files you are trying to read in. You could sit there an copy and paste the file names, but what if you had 20+ files? It's not very efficient. Instead, let R do the hard work for you and find the names itself.

Let's look at the recent Adidas pitch data. There were only two files, but this principle will work no matter how many there are. First, we update are working directory so R knows where the files are saved. Then, as we know all of our files are csvs, we ask are to create an object called `paths` which is a list of all the csv files in the directory.

```{r setwd}
setwd("/Volumes/GoogleDrive/My Drive/Share_Clients/Data Science Project Work/Slack Overflow/reading_multiple_files/data")

paths <- list.files(pattern = "csv$", recursive = TRUE)
paths

```

R has correctly identified the two datafiles in the path. Now it's time to read them in.

## Using map() to call the same function on multiple objects

`map()` is a special function that allows you to conduct another function over multiple objects at the same time. When you think about it, it's exactly the kind of thing we need here. We need to call `read_csv()` multiple times and `map()` is going to save us so much time by doing all of those processes at once. The code to do so is very simple:

```{r map, warning=FALSE, message=FALSE}
all_docs <- map(paths, read_csv)

```

R has created an object called `all_docs` which is the result reading in all the csvs. Great! We aren't quite there though because at the moment, whilst all the data is in our R environment, they are living as separate objects in that list. We need to bind them all together. For that, we can use a `full_join()`

```{r data}
data <- reduce(all_docs, full_join)
data
```


So there were are - all the data exports loaded in and bound into one object quickly and efficiently!